{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import Bio.PDB.Polypeptide as pp\n",
    "from collections import Counter\n",
    "import freesasa\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = list(pp.aa1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_path = \"../../../Dropbox/perturbation_networks/draft/figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = ['1be9', '1d5r', '1nd4', '3dqw', '4bz3']\n",
    "protein_names = ['PSD95', 'PTEN', 'APH(3\\')II', 'Src CD', 'VIM-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import processed functional data as DataFrames, all files have ordered AA list as index, positions as columns\n",
    "# Save data in functional_data\n",
    "functional_data = dict()\n",
    "for protein in proteins:\n",
    "    csv_file = os.path.join(DATA, f'functional_{protein}.csv')\n",
    "    functional_data[protein] = pd.read_csv(csv_file, index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturbation Network Data and Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(DATA, 'structure')\n",
    "thresholds = [round(i, 1) for i in np.linspace(3, 10, 71)]\n",
    "sample_thresholds = [round(i, 1) for i in np.linspace(3, 10, 8)]\n",
    "measures = ['nodes', 'edges', 'weight', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadNetworkCSV(protein, threshold, measure):\n",
    "    \"\"\"Return DataFrame from corresponding CSV. If protein has multiple identical chains, return average value for \n",
    "    each position amongst all chains.\"\"\"\n",
    "    file = os.path.join(data_path, f\"{protein}/{protein}_{threshold}_{measure}.csv\")\n",
    "    network_df = pd.read_csv(file, header=0)\n",
    "    network_df.index = AA\n",
    "    # Get chains from columns\n",
    "    column_names = list(network_df.columns)\n",
    "    chains = list(set([position[1] for position in column_names]))\n",
    "    # Get positions without chain distinction from functional files\n",
    "    positions = list(functional_data[protein].columns)\n",
    "    average = pd.DataFrame(index=AA, columns=positions, dtype=np.float64)\n",
    "    # Save data for position over chains in list, write average into df\n",
    "    for position in positions:\n",
    "        for aa in AA:\n",
    "            values = []\n",
    "            for chain in chains:\n",
    "                check = position[0]+chain+position[1:]\n",
    "                if check in network_df.columns:\n",
    "                    values.append(network_df.at[aa, check])\n",
    "            if values:\n",
    "                average_value = sum(values)/len(values)\n",
    "                average.at[aa, position] = average_value\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardize(protein, threshold, measure):\n",
    "    \"\"\"Return standardized values from network data. Make 0's into NaN. \"\"\"\n",
    "    network_df = ReadNetworkCSV(protein, threshold, measure)\n",
    "    for position in network_df.columns:\n",
    "        for aa in network_df.index:\n",
    "            if position[0] == aa:\n",
    "                network_df.at[aa, position] = np.nan\n",
    "    data_array = network_df.to_numpy()\n",
    "    data_mean = np.nanmean(network_df, dtype=np.float64)\n",
    "    data_std = np.nanstd(network_df, dtype=np.float64)\n",
    "    network_df = network_df.apply(lambda x:(x-data_mean)/data_std)\n",
    "    return network_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPercentage(percentage, which, data, return_score=False):\n",
    "    \"\"\"Return set with top or bottom percentage of positions according to functional data. \n",
    "    Parameters:\n",
    "        percentage (float): between 0 and 1, percentage of positions that we want.\n",
    "        which (str): 'highest', 'lowest'\n",
    "        data (dataframe): functional data to consider mean of\n",
    "        return_score (bool): If True, return list of tuples with mean value and position\n",
    "    Returns:\n",
    "        Set of positions.\n",
    "    \"\"\"\n",
    "    functional_mean = data.mean()\n",
    "    positions = list(data.columns)\n",
    "    pairs = [(functional_mean[pos], pos) for pos in positions] \n",
    "    pairs.sort(key = lambda x:x[0]) \n",
    "    if which == 'highest': \n",
    "        pairs.reverse() \n",
    "    n = int(len(positions)*percentage)\n",
    "    if return_score:\n",
    "        return [pair for pair in pairs[:n]]\n",
    "    else:\n",
    "        return set([pair[1] for pair in pairs[:n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSD(sd, data):\n",
    "    \"\"\" Return set with positions with mean scores above (if sd > 0) or below (if sd < 0) sd according to \n",
    "    functional data.\"\"\"\n",
    "    functional_mean = data.mean()\n",
    "    positions = list(data.columns)\n",
    "    if sd > 0:\n",
    "        return set([pos for pos in positions if functional_mean[pos] > sd])\n",
    "    else: \n",
    "        return set([pos for pos in positions if functional_mean[pos] < sd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNetworkExtremes(protein, mincount, measure_cutoffs, thresh=9.0):\n",
    "    \"\"\" Return set with positions that pass measure sd cutoffs for at least mincount measures. \"\"\"\n",
    "    network_extremes_list = []\n",
    "    for i,measure in enumerate(measures): \n",
    "        threshold = 3.8 if measure == 'distance' else thresh\n",
    "        network_df = Standardize(protein, threshold, measure)\n",
    "        if measure_cutoffs[i] > 0:\n",
    "            extremes = network_df.columns[(network_df > measure_cutoffs[i]).any()].tolist()\n",
    "        else:\n",
    "            extremes = network_df.columns[(network_df < measure_cutoffs[i]).any()].tolist()\n",
    "        network_extremes_list.extend(extremes)\n",
    "\n",
    "    counter = Counter(network_extremes_list)\n",
    "    positions = list(set(network_extremes_list))\n",
    "    return set([pos for pos in positions if counter[pos] >= mincount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToPercentage(a,b):\n",
    "    \"\"\"Return percentage form of a/b, if b != 0. If given set or list, use len of. \n",
    "    If string, return formatted percentage, else float.\"\"\"\n",
    "    x = a if type(a) == int or type(a) == float else len(a)\n",
    "    y = b if type(b) == int or type(b) == float else len(b)\n",
    "    \n",
    "    if y == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return round(100*x/y,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating buriedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output from buriedness.py is in DATA/output/output_{protein}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetList(protein, mincount, measure_cutoffs, thresh=9.0, loss=True):\n",
    "    \"\"\"Get list with predicted positions, AA in three letter code. If loss==False, use complement for gain preds\"\"\"\n",
    "    pos = GetNetworkExtremes(protein, mincount, measure_cutoffs, thresh=thresh)\n",
    "    if not loss:\n",
    "        total_pos = functional_data[protein].columns\n",
    "        complement = [i for i in total_pos if i not in pos]\n",
    "        pos = complement\n",
    "    positions = map(lambda x:pp.one_to_three(x[0])+x[1:], pos)\n",
    "    return list(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_path = os.path.join(DATA, 'pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "buriedness_data = dict()\n",
    "for protein in proteins:\n",
    "    file = os.path.join(DATA, f\"output/output_{protein}.csv\")\n",
    "    df = pd.read_csv(file)\n",
    "    df.columns = ['residue', 'buriedness']\n",
    "    df = df[~df.residue.str.contains('HOH')] # remove water\n",
    "    predictions = GetList(protein, 4, [1.5]*4) # predictions maximizing accuracy\n",
    "    df = df.set_index('residue')\n",
    "    buriedness_data[protein] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for protein in proteins:\n",
    "    structure = freesasa.Structure(os.path.join(pdb_path, f\"{protein}.pdb\"))\n",
    "    result = freesasa.calc(structure)\n",
    "    area_classes = freesasa.classifyResults(result, structure)\n",
    "    d = result.residueAreas()\n",
    "    for chain in d:\n",
    "        for position in d[chain]:\n",
    "            key = chain+d[chain][position].residueType+position \n",
    "            buriedness_data[protein].at[key, 'ASA'] = d[chain][position].total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## classifying as predicted for loss, gain or none \n",
    "## esta parte se deberia poder hacer de una forma mas eficiente, pero no se como :(\n",
    "for protein in proteins:\n",
    "    loss = GetList(protein, 4, [1.5]*4)\n",
    "    gain = GetList(protein, 1, [1]*4, loss=False)\n",
    "    df = buriedness_data[protein]\n",
    "    for position in df.index:\n",
    "        for pred in loss:\n",
    "            if pred in position:\n",
    "                df.at[position, 'prediction'] = 'loss'\n",
    "        for pred in gain:\n",
    "            if pred in position:\n",
    "                df.at[position, 'prediction'] = 'gain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Getting position numbers to color in pdbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss \n",
    "for protein in proteins:\n",
    "    predictions = GetNetworkExtremes(protein, 4, [1.5]*4)\n",
    "    numbers = [int(x[1:]) for x in predictions]\n",
    "    print(protein, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gain \n",
    "for protein in proteins:\n",
    "    predictions = GetNetworkExtremes(protein, 1, [1]*4)\n",
    "    total_positions = functional_data[protein].columns\n",
    "    numbers = [int(x[1:]) for x in total_positions if x not in predictions]\n",
    "    print(protein, numbers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
